{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff67c737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae442b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from Functions import Basic_info_func, Remove_outliers_with_lof, Select_k_best_features\n",
    "\n",
    "# importing important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04ef09",
   "metadata": {},
   "source": [
    "Path = /OneDrive/Desktop/MS-AAi/Course_500_Probability/Project_AAI500-A1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b89890a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset \n",
    "df = pd.read_csv('./Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f63a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_variables = df.drop('critical_temp', axis = 1)\n",
    "target_variable = df['critical_temp']\n",
    "    \n",
    "train_X, test_X, train_y, test_y = train_test_split(independent_variables, target_variable, \n",
    "                                                    test_size=0.2, random_state=0, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690880d1",
   "metadata": {},
   "source": [
    "### Outlier Detection and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "008803fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine the number of features and calculate the number of subplots needed\n",
    "# num_features = len(train_X)\n",
    "\n",
    "# # Create the subplots\n",
    "# sns.set_style('darkgrid')\n",
    "# fig, ax = plt.subplots(9, 9, figsize=(15, 10))\n",
    "\n",
    "# # Flatten the axes array for easy iteration\n",
    "# ax_flat = ax.flatten()\n",
    "\n",
    "# # Iterate over each element property and corresponding axis\n",
    "# for property_name, axis in zip(train_X, ax_flat):\n",
    "#     sns.kdeplot(data=df, x=property_name , ax=axis)\n",
    "\n",
    "# # Hide empty subplots if any\n",
    "# for axis in ax_flat[num_features:]:\n",
    "#     axis.axis('off')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.suptitle('Distribution of independent features', fontsize=16, y=1.05)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a278f0",
   "metadata": {},
   "source": [
    "Notice that we have features that seem to have some extereme values, such as wtd_range_FusionHeat and mean_Density. In order to tackle these extremet points we can use a Machine lerning approch named local outlier factor that can help us predicting outliers and removing them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28bb97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before outlier removal:\n",
      "(17010, 82)\n",
      "\n",
      "Shape after outlier removal:\n",
      "(16159, 82)\n"
     ]
    }
   ],
   "source": [
    "new_train_X, new_train_y  = Remove_outliers_with_lof(train_X, train_y, contamination = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29a48b",
   "metadata": {},
   "source": [
    "#### Features Selection\n",
    "\n",
    "In the data analysis part we observed that our entire data has many highly colinear features that causes multi colinearity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce8aa5",
   "metadata": {},
   "source": [
    "### Linear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297b6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_train_X = scaler.fit_transform(new_train_X)\n",
    "scaled_test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bad36f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results \n",
      " - - - - - - - - - - - - - - - - - - - - \n",
      "Training RMSE: 17.33268\n",
      "Training MAE: 13.09352\n",
      "Training R2_score: 0.74299\n",
      "Testing results \n",
      " - - - - - - - - - - - - - - - - - - - - \n",
      "Testing RMSE: 17.54252\n",
      "Testing MAE: 13.39577\n",
      "Testing R2_score: 0.73560\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize the linear regression model\n",
    "simple_linear_regression = LinearRegression()\n",
    "\n",
    "# Step 3: Fit the model on the scaled training data\n",
    "simple_linear_regression.fit(scaled_train_X, new_train_y)\n",
    "\n",
    "# Step 4: Predict on the training set\n",
    "train_preds = simple_linear_regression.predict(scaled_train_X)\n",
    "\n",
    "# Training evaluation\n",
    "print('Training results', '\\n', '- '*20)\n",
    "RMSE = np.sqrt(mean_squared_error(new_train_y, train_preds))\n",
    "MAE = mean_absolute_error(new_train_y, train_preds)\n",
    "R2_score = r2_score(new_train_y, train_preds)\n",
    "\n",
    "print(f'Training RMSE: {RMSE:.5f}')\n",
    "print(f'Training MAE: {MAE:.5f}')\n",
    "print(f'Training R2_score: {R2_score:.5f}')\n",
    "\n",
    "\n",
    "# Testing Results\n",
    "test_preds = simple_linear_regression.predict(scaled_test_X)\n",
    "\n",
    "#Testing evaluation\n",
    "print('Testing results', '\\n', '- '*20)\n",
    "RMSE_test = np.sqrt(mean_squared_error(test_y, test_preds))\n",
    "MAE_test = mean_absolute_error(test_y, test_preds)\n",
    "R2_score_test = r2_score(test_y, test_preds)\n",
    "\n",
    "print(f'Testing RMSE: {RMSE_test:.5f}')\n",
    "print(f'Testing MAE: {MAE_test:.5f}')\n",
    "print(f'Testing R2_score: {R2_score_test:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd72655",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a660b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75527d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results \n",
      " - - - - - - - - - - - - - - - - - - - - \n",
      "Training RMSE: 8.66638\n",
      "Training MAE: 5.76139\n",
      "Training R2_score: 0.93575\n",
      "Testing results \n",
      " - - - - - - - - - - - - - - - - - - - - \n",
      "Testing RMSE: 10.83460\n",
      "Testing MAE: 6.96043\n",
      "Testing R2_score: 0.89914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Step 2: Initialize the Gradient Boosting Regressor model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Step 3: Fit the model on the scaled training data\n",
    "gb_model.fit(scaled_train_X, new_train_y)\n",
    "\n",
    "# Step 4: Predict on the training set\n",
    "train_preds = gb_model.predict(scaled_train_X)\n",
    "\n",
    "# Training evaluation\n",
    "print('Training results', '\\n', '- '*20)\n",
    "RMSE = np.sqrt(mean_squared_error(new_train_y, train_preds))\n",
    "MAE = mean_absolute_error(new_train_y, train_preds)\n",
    "R2_score = r2_score(new_train_y, train_preds)\n",
    "\n",
    "print(f'Training RMSE: {RMSE:.5f}')\n",
    "print(f'Training MAE: {MAE:.5f}')\n",
    "print(f'Training R2_score: {R2_score:.5f}')\n",
    "\n",
    "# Step 5: Predict on the testing set\n",
    "test_preds = gb_model.predict(scaled_test_X)\n",
    "\n",
    "# Testing evaluation\n",
    "print('Testing results', '\\n', '- '*20)\n",
    "RMSE_test = np.sqrt(mean_squared_error(test_y, test_preds))\n",
    "MAE_test = mean_absolute_error(test_y, test_preds)\n",
    "R2_score_test = r2_score(test_y, test_preds)\n",
    "\n",
    "print(f'Testing RMSE: {RMSE_test:.5f}')\n",
    "print(f'Testing MAE: {MAE_test:.5f}')\n",
    "print(f'Testing R2_score: {R2_score_test:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8e0c2",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97984792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results \n",
      " - - - - - - - - - - - - - - - - - - - - \n",
      "Training RMSE: 5.72527\n",
      "Training MAE: 3.61011\n",
      "Training R2_score: 0.97196\n",
      "Testing results \n",
      " - - - - - - - - - - - - - - - - - - - - \n",
      "Testing RMSE: 11.57016\n",
      "Testing MAE: 6.92357\n",
      "Testing R2_score: 0.88498\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Step 2: Initialize the XGBoost Regressor model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, learning_rate=0.9, max_depth=3, random_state=42)\n",
    "\n",
    "# Step 3: Fit the model on the scaled training data\n",
    "xgb_model.fit(scaled_train_X, new_train_y)\n",
    "\n",
    "# Step 4: Predict on the training set\n",
    "train_preds = xgb_model.predict(scaled_train_X)\n",
    "\n",
    "# Training evaluation\n",
    "print('Training results', '\\n', '- '*20)\n",
    "RMSE = np.sqrt(mean_squared_error(new_train_y, train_preds))\n",
    "MAE = mean_absolute_error(new_train_y, train_preds)\n",
    "R2_score = r2_score(new_train_y, train_preds)\n",
    "\n",
    "print(f'Training RMSE: {RMSE:.5f}')\n",
    "print(f'Training MAE: {MAE:.5f}')\n",
    "print(f'Training R2_score: {R2_score:.5f}')\n",
    "\n",
    "# Step 5: Predict on the testing set\n",
    "test_preds = xgb_model.predict(scaled_test_X)\n",
    "\n",
    "# Testing evaluation\n",
    "print('Testing results', '\\n', '- '*20)\n",
    "RMSE_test = np.sqrt(mean_squared_error(test_y, test_preds))\n",
    "MAE_test = mean_absolute_error(test_y, test_preds)\n",
    "R2_score_test = r2_score(test_y, test_preds)\n",
    "\n",
    "print(f'Testing RMSE: {RMSE_test:.5f}')\n",
    "print(f'Testing MAE: {MAE_test:.5f}')\n",
    "print(f'Testing R2_score: {R2_score_test:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b5c2a8",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b5aaa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m20,992\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,257</span> (251.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64,257\u001b[0m (251.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,257</span> (251.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64,257\u001b[0m (251.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 739.0274 - mae: 17.6597 - mse: 739.0274 - val_loss: 252.0211 - val_mae: 10.7636 - val_mse: 252.0211\n",
      "Epoch 2/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 290.9916 - mae: 11.5055 - mse: 290.9916 - val_loss: 242.4658 - val_mae: 10.6667 - val_mse: 242.4658\n",
      "Epoch 3/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 273.8766 - mae: 11.0124 - mse: 273.8766 - val_loss: 219.0945 - val_mae: 9.9371 - val_mse: 219.0945\n",
      "Epoch 4/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 257.6720 - mae: 10.7686 - mse: 257.6720 - val_loss: 223.6095 - val_mae: 10.2685 - val_mse: 223.6095\n",
      "Epoch 5/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 262.3363 - mae: 10.8341 - mse: 262.3363 - val_loss: 222.4342 - val_mae: 10.3191 - val_mse: 222.4342\n",
      "Epoch 6/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 258.5431 - mae: 10.7133 - mse: 258.5431 - val_loss: 204.4885 - val_mae: 9.5105 - val_mse: 204.4885\n",
      "Epoch 7/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 244.6171 - mae: 10.4744 - mse: 244.6171 - val_loss: 199.1427 - val_mae: 9.3973 - val_mse: 199.1427\n",
      "Epoch 8/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 232.5579 - mae: 10.0948 - mse: 232.5579 - val_loss: 213.4185 - val_mae: 10.1232 - val_mse: 213.4185\n",
      "Epoch 9/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 229.3843 - mae: 10.0018 - mse: 229.3843 - val_loss: 207.1572 - val_mae: 9.9281 - val_mse: 207.1572\n",
      "Epoch 10/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 225.6068 - mae: 9.9120 - mse: 225.6068 - val_loss: 192.5385 - val_mae: 9.4817 - val_mse: 192.5385\n",
      "Epoch 11/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 227.0009 - mae: 10.0186 - mse: 227.0009 - val_loss: 192.4716 - val_mae: 9.3509 - val_mse: 192.4716\n",
      "Epoch 12/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 215.0591 - mae: 9.7613 - mse: 215.0591 - val_loss: 223.5671 - val_mae: 10.4051 - val_mse: 223.5671\n",
      "Epoch 13/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 209.0875 - mae: 9.6730 - mse: 209.0875 - val_loss: 179.7873 - val_mae: 8.8730 - val_mse: 179.7873\n",
      "Epoch 14/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 213.0064 - mae: 9.6067 - mse: 213.0064 - val_loss: 185.4488 - val_mae: 9.1879 - val_mse: 185.4488\n",
      "Epoch 15/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 211.9312 - mae: 9.6399 - mse: 211.9312 - val_loss: 174.0337 - val_mae: 8.6411 - val_mse: 174.0337\n",
      "Epoch 16/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 207.6086 - mae: 9.5450 - mse: 207.6086 - val_loss: 173.2543 - val_mae: 8.6703 - val_mse: 173.2543\n",
      "Epoch 17/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 206.7592 - mae: 9.4415 - mse: 206.7592 - val_loss: 187.0839 - val_mae: 9.4067 - val_mse: 187.0839\n",
      "Epoch 18/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 207.1830 - mae: 9.4972 - mse: 207.1830 - val_loss: 180.2514 - val_mae: 9.0359 - val_mse: 180.2514\n",
      "Epoch 19/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 198.5054 - mae: 9.3102 - mse: 198.5054 - val_loss: 181.3896 - val_mae: 9.1502 - val_mse: 181.3896\n",
      "Epoch 20/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 192.4301 - mae: 9.1854 - mse: 192.4301 - val_loss: 218.8772 - val_mae: 10.1985 - val_mse: 218.8772\n",
      "Epoch 21/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 203.1504 - mae: 9.3992 - mse: 203.1504 - val_loss: 180.6468 - val_mae: 8.9723 - val_mse: 180.6468\n",
      "Epoch 22/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 201.9325 - mae: 9.3488 - mse: 201.9325 - val_loss: 192.9115 - val_mae: 9.4843 - val_mse: 192.9115\n",
      "Epoch 23/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 194.2049 - mae: 9.2152 - mse: 194.2049 - val_loss: 194.8176 - val_mae: 9.6686 - val_mse: 194.8176\n",
      "Epoch 24/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 192.5620 - mae: 9.1300 - mse: 192.5620 - val_loss: 180.3996 - val_mae: 9.1491 - val_mse: 180.3996\n",
      "Epoch 25/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 181.1764 - mae: 8.9390 - mse: 181.1764 - val_loss: 167.7014 - val_mae: 8.5750 - val_mse: 167.7014\n",
      "Epoch 26/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 190.5148 - mae: 9.0824 - mse: 190.5148 - val_loss: 158.1858 - val_mae: 8.4383 - val_mse: 158.1858\n",
      "Epoch 27/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 187.4905 - mae: 9.0627 - mse: 187.4905 - val_loss: 182.0411 - val_mae: 9.2869 - val_mse: 182.0411\n",
      "Epoch 28/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 181.5518 - mae: 8.9434 - mse: 181.5518 - val_loss: 217.0242 - val_mae: 10.2036 - val_mse: 217.0242\n",
      "Epoch 29/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 181.7683 - mae: 8.9095 - mse: 181.7683 - val_loss: 206.3456 - val_mae: 9.9485 - val_mse: 206.3456\n",
      "Epoch 30/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 180.2015 - mae: 8.8931 - mse: 180.2015 - val_loss: 211.4579 - val_mae: 10.0562 - val_mse: 211.4579\n",
      "Epoch 31/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 178.6867 - mae: 8.9108 - mse: 178.6867 - val_loss: 169.8792 - val_mae: 8.8251 - val_mse: 169.8792\n",
      "Epoch 32/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 178.4409 - mae: 8.7941 - mse: 178.4409 - val_loss: 168.4212 - val_mae: 8.7677 - val_mse: 168.4212\n",
      "Epoch 33/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 178.0564 - mae: 8.7982 - mse: 178.0564 - val_loss: 170.7251 - val_mae: 8.8928 - val_mse: 170.7251\n",
      "Epoch 34/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 173.8429 - mae: 8.6404 - mse: 173.8429 - val_loss: 254.7086 - val_mae: 10.9225 - val_mse: 254.7086\n",
      "Epoch 35/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 177.4739 - mae: 8.8383 - mse: 177.4739 - val_loss: 169.5485 - val_mae: 8.8514 - val_mse: 169.5485\n",
      "Epoch 36/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 183.0760 - mae: 8.9159 - mse: 183.0760 - val_loss: 226.3754 - val_mae: 10.2075 - val_mse: 226.3754\n",
      "Epoch 37/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 174.9847 - mae: 8.7605 - mse: 174.9847 - val_loss: 216.5054 - val_mae: 9.9639 - val_mse: 216.5054\n",
      "Epoch 38/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 173.1879 - mae: 8.7441 - mse: 173.1879 - val_loss: 185.9312 - val_mae: 9.4061 - val_mse: 185.9312\n",
      "Epoch 39/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 170.4456 - mae: 8.6095 - mse: 170.4456 - val_loss: 188.3248 - val_mae: 9.3043 - val_mse: 188.3248\n",
      "Epoch 40/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 178.3347 - mae: 8.7551 - mse: 178.3347 - val_loss: 173.5605 - val_mae: 9.0411 - val_mse: 173.5605\n",
      "Epoch 41/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 164.3064 - mae: 8.4584 - mse: 164.3064 - val_loss: 165.8515 - val_mae: 8.8439 - val_mse: 165.8515\n",
      "Epoch 42/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 164.5977 - mae: 8.4085 - mse: 164.5977 - val_loss: 198.4145 - val_mae: 9.7249 - val_mse: 198.4145\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 165.7433 - mae: 8.5611 - mse: 165.7433 - val_loss: 197.9593 - val_mae: 9.7248 - val_mse: 197.9593\n",
      "Epoch 44/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 167.1530 - mae: 8.4956 - mse: 167.1530 - val_loss: 232.1774 - val_mae: 10.4888 - val_mse: 232.1774\n",
      "Epoch 45/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 167.1766 - mae: 8.5741 - mse: 167.1766 - val_loss: 216.1949 - val_mae: 10.0361 - val_mse: 216.1949\n",
      "Epoch 46/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 161.1931 - mae: 8.4044 - mse: 161.1931 - val_loss: 209.8995 - val_mae: 9.9103 - val_mse: 209.8995\n",
      "Epoch 47/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 156.9740 - mae: 8.3190 - mse: 156.9740 - val_loss: 188.4961 - val_mae: 9.4533 - val_mse: 188.4961\n",
      "Epoch 48/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 167.3379 - mae: 8.5096 - mse: 167.3379 - val_loss: 196.3246 - val_mae: 9.6402 - val_mse: 196.3246\n",
      "Epoch 49/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 162.8339 - mae: 8.3887 - mse: 162.8339 - val_loss: 225.2652 - val_mae: 10.2983 - val_mse: 225.2652\n",
      "Epoch 50/50\n",
      "\u001b[1m404/404\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 164.4737 - mae: 8.4450 - mse: 164.4737 - val_loss: 170.2695 - val_mae: 8.9955 - val_mse: 170.2695\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step\n",
      "Training results:\n",
      "Training RMSE: 12.66488\n",
      "Training MAE: 8.73356\n",
      "Training R2_score: 0.86278\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step\n",
      "\n",
      "Testing results:\n",
      "Testing RMSE: 13.55153\n",
      "Testing MAE: 9.42326\n",
      "Testing R2_score: 0.84222\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(scaled_train_X.shape[1],)),\n",
    "    Dropout(0.4),  # Example of adding dropout for regularization\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression task\n",
    "])\n",
    "\n",
    "# Compile the model with appropriate optimizer and loss function\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae', 'mse'])\n",
    "\n",
    "# Print the model summary to understand the architecture and number of parameters\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(scaled_train_X, new_train_y, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate on training set\n",
    "train_preds = model.predict(scaled_train_X)\n",
    "train_rmse = np.sqrt(mean_squared_error(new_train_y, train_preds))\n",
    "train_mae = mean_absolute_error(new_train_y, train_preds)\n",
    "train_r2 = r2_score(new_train_y, train_preds)\n",
    "\n",
    "print('Training results:')\n",
    "print(f'Training RMSE: {train_rmse:.5f}')\n",
    "print(f'Training MAE: {train_mae:.5f}')\n",
    "print(f'Training R2_score: {train_r2:.5f}')\n",
    "\n",
    "# Evaluate on test set\n",
    "test_preds = model.predict(scaled_test_X)\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_preds))\n",
    "test_mae = mean_absolute_error(test_y, test_preds)\n",
    "test_r2 = r2_score(test_y, test_preds)\n",
    "\n",
    "print('\\nTesting results:')\n",
    "print(f'Testing RMSE: {test_rmse:.5f}')\n",
    "print(f'Testing MAE: {test_mae:.5f}')\n",
    "print(f'Testing R2_score: {test_r2:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aad52955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/e1/4c/4685ccfae9806f561de716e32549190c1f533dde5bcadaf83bdf23972cf0/lightgbm-4.3.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.3.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in c:\\apps\\anaconda\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\apps\\anaconda\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Downloading lightgbm-4.3.0-py3-none-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.3 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.3 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.2/1.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.2/1.3 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 6.1 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b18337c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's rmse: 8.04868\ttraining's l1: 5.28546\tvalid_1's rmse: 10.4552\tvalid_1's l1: 6.61845\n",
      "Training results:\n",
      "Training RMSE: 8.04868\n",
      "Training MAE: 5.28546\n",
      "Training R2_score: 0.94458\n",
      "\n",
      "Testing results:\n",
      "Testing RMSE: 10.45525\n",
      "Testing MAE: 6.61845\n",
      "Testing R2_score: 0.90608\n"
     ]
    }
   ],
   "source": [
    "# Import the early stopping callback\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "# Train the model with early stopping callback\n",
    "model = lgb.train(\n",
    "    params, \n",
    "    train_data, \n",
    "    num_boost_round=1000, \n",
    "    valid_sets=[train_data, test_data], \n",
    "    callbacks=[early_stopping(stopping_rounds=100)]\n",
    ")\n",
    "\n",
    "# The rest of the code remains the same\n",
    "train_preds = model.predict(scaled_train_X, num_iteration=model.best_iteration)\n",
    "test_preds = model.predict(scaled_test_X, num_iteration=model.best_iteration)\n",
    "\n",
    "# Evaluate the model\n",
    "train_rmse = mean_squared_error(new_train_y, train_preds, squared=False)\n",
    "train_mae = mean_absolute_error(new_train_y, train_preds)\n",
    "train_r2 = r2_score(new_train_y, train_preds)\n",
    "\n",
    "print('Training results:')\n",
    "print(f'Training RMSE: {train_rmse:.5f}')\n",
    "print(f'Training MAE: {train_mae:.5f}')\n",
    "print(f'Training R2_score: {train_r2:.5f}')\n",
    "\n",
    "test_rmse = mean_squared_error(test_y, test_preds, squared=False)\n",
    "test_mae = mean_absolute_error(test_y, test_preds)\n",
    "test_r2 = r2_score(test_y, test_preds)\n",
    "\n",
    "print('\\nTesting results:')\n",
    "print(f'Testing RMSE: {test_rmse:.5f}')\n",
    "print(f'Testing MAE: {test_mae:.5f}')\n",
    "print(f'Testing R2_score: {test_r2:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7d79a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best parameters: {'subsample': 0.8, 'n_estimators': 1000, 'max_depth': 8, 'learning_rate': 0.03, 'colsample_bytree': 0.6}\n",
      "Training results:\n",
      "Training RMSE: 4.57896\n",
      "Training MAE: 2.43766\n",
      "Training R2_score: 0.98206\n",
      "\n",
      "Testing results:\n",
      "Testing RMSE: 9.80910\n",
      "Testing MAE: 5.46102\n",
      "Testing R2_score: 0.91733\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'n_estimators': [100, 200, 500, 1000]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', seed=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, \n",
    "                                 scoring='neg_mean_squared_error', n_iter=50, \n",
    "                                 cv=5, verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(scaled_train_X, new_train_y)\n",
    "\n",
    "# Best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Train with the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "model = xgb.XGBRegressor(**best_params, objective='reg:squarederror', seed=42)\n",
    "model.fit(scaled_train_X, new_train_y)\n",
    "\n",
    "# Make predictions\n",
    "train_preds = model.predict(scaled_train_X)\n",
    "test_preds = model.predict(scaled_test_X)\n",
    "\n",
    "# Evaluate the model\n",
    "train_rmse = mean_squared_error(new_train_y, train_preds, squared=False)\n",
    "train_mae = mean_absolute_error(new_train_y, train_preds)\n",
    "train_r2 = r2_score(new_train_y, train_preds)\n",
    "\n",
    "print('Training results:')\n",
    "print(f'Training RMSE: {train_rmse:.5f}')\n",
    "print(f'Training MAE: {train_mae:.5f}')\n",
    "print(f'Training R2_score: {train_r2:.5f}')\n",
    "\n",
    "test_rmse = mean_squared_error(test_y, test_preds, squared=False)\n",
    "test_mae = mean_absolute_error(test_y, test_preds)\n",
    "test_r2 = r2_score(test_y, test_preds)\n",
    "\n",
    "print('\\nTesting results:')\n",
    "print(f'Testing RMSE: {test_rmse:.5f}')\n",
    "print(f'Testing MAE: {test_mae:.5f}')\n",
    "print(f'Testing R2_score: {test_r2:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d4f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
